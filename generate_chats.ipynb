{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dedab4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests as re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import openai\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "import os\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "# everyDct | overview dict (ie. 'CrazyOnes50VideoIDs.json') \n",
    "# all_thumbnails | list of all thumbnails (ordered by id)\n",
    "# \n",
    "\n",
    "\n",
    "def retreiveAllVideoIds(channelID, theType):\n",
    "    req = requests.get(\"https://www.googleapis.com/youtube/v3/search?part=snippet&type=\" + str(theType) + \"&channelId=\" + str(channelID) + \"&key=AIzaSyC1L4ofqAGmKOVvCS2n0Vzi4h4q4Abit74&maxResults=50&videoDuration=long\")\n",
    "    return req.json()\n",
    "\n",
    "\n",
    "# Creates everyDct\n",
    "def get_everyDct(channelId, name):\n",
    "    dct = retreiveAllVideoIds(channelId, \"video\")\n",
    "    with open(str(name) + \".json\", 'w') as ids:\n",
    "        json.dump(dct, ids)\n",
    "    return dct\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3f6879a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "d\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "everyDct = None\n",
    "ans = None\n",
    "ids = None\n",
    "timestamps = None\n",
    "transcripts = None\n",
    "segmented_transcripts = None\n",
    "diffDct = None\n",
    "overArchingDct = None\n",
    "\n",
    "def generate_everything(channelId):\n",
    "    global everyDct\n",
    "    everyDct = get_everyDct(channelId, \"lex\")\n",
    "   \n",
    "    global ans\n",
    "    ans = get_thumbnails(everyDct)\n",
    "    \n",
    "    print(\"T\")\n",
    "    \n",
    "    global ids\n",
    "    ids = get_ids()\n",
    "    print('d')\n",
    "    \n",
    "    global timestamps\n",
    "    timestamps = get_timestamps()\n",
    "    \n",
    "    global transcripts\n",
    "    transcripts = get_transcripts(ids)\n",
    "    \n",
    "    print('s')\n",
    "    \n",
    "    global segmented_transcripts\n",
    "    segmented_transcripts = create_corrected_dct_for_channel()\n",
    "    \n",
    "    global diffDct\n",
    "    diffDct = turn_to_embeddings()\n",
    "    \n",
    "    global overArchingDct\n",
    "    overArchingDct = diffDct\n",
    "\n",
    "generate_everything(\"UCESLZhusAkFfsNsApnjF_Cg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c374d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = answer(\"Should I pull my money from regional banks?\", \"You are the hosts of the All in Pod, famous and extremely rich investors who explicitly give financial advice.\")\n",
    "print(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6edc8643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5a6c0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97ec15e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fdda9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4771946b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64510af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a2ccb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what made you excited\n",
      "to take this meeting? And I just think it is the best lesson\n",
      "for entrepreneurs who think either\n",
      "they think they're great salespeople or they're trying\n",
      "to figure out how to sell and they haven't really done it before\n",
      "and they just assume they have to start talking and selling\n",
      "and storytelling in the business. And to me, that is the biggest mistake. Rather than taking in the information\n",
      "like why is the person here? What are they looking to\n",
      "basically hear from you such that it is going to make an easy decision\n",
      "for them to invest? So I think that was a brilliant question\n",
      "by you, Sofia. You want to have the next one. Let's talk\n",
      "about how to make seven figures in a year. Yeah, this was a tweet that I think Alex you made right and it's super interesting. I mean, there's just this whole kind\n",
      "of Twitter world of people being like, you know, I found a dry cleaner business\n",
      "and I turn it into like a 50 all these, like, kind of niche businesses\n",
      "that like, you know, people are really mostly talking\n",
      "about bootstrapping. And there are incredible ideas out there. And I think it just got our wheels\n",
      "spinning on. If you had if you needed to build\n",
      "$1,000,000 business in 12 months, where would you go? What would you choose? And so I think there were\n",
      "a lot of ideas on there. I think a lot of them\n",
      "are super interesting. But I'm curious what what you would do. Well well you need to lead this off\n",
      "because you're actually doing it for addressing it. I just hypothetical. So what you're doing. All right. Well, I did it so in 20, 20,\n",
      "10\n",
      "[[33, '- Intro'], [114, ') - The Rundown'], [148, ') - Quick history of Spotify Wrapped'], [183, ') - Jesseâ€™s Spotify Wrapped'], [290, ') - Sophiaâ€™s Spotify Wrapped'], [440, ') - Alexâ€™s Spotify Wrapped'], [512, ') - What makes Spotify Wrapped so successful'], [778, ') - The rumored origin story of Spotify Wrapped'], [883, ') - The team brainstorms how to apply the lessons from Spotify Wrapped to your their own businesses'], [1347, ') - Jesseâ€™s experience of the process selling a business'], [1717, ') - Why Alex and Austin decided to sell Morning Brew, and what Alex thinks about the reasons to sell a business'], [1986, ') - Sophiaâ€™s experience of selling Girlboss'], [2045, ') - What Sophia potentially could have made on selling Nasty Gal'], [2133, ') - Why itâ€™s okay to sell a business when youâ€™re early in your career'], [2265, ') - The grueling nature of the process of selling your business'], [2521, ') - The one thing Jesse, Sophia, and Alex would do differently if they were re-doing the sales of their business'], [2674, ') - Thumbs Up/Thumbs Down']]\n",
      "('https://www.youtube.com/watch?v=FdKS9F9e1eI&t=1585s', 'Liquid Death&#39;s $700M Valuation &amp; The Hidden Truth of Becoming A Tech Entrepreneur', 'Video')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f4081f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": null,\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Investing in good companies is not just about selecting companies with good narratives or stories. It takes a lot of effort to understand a company's income statement, balance sheet, and cash flow, as well as the broader context of all the things that could go wrong or right in the future. Moreover, not all good companies are good investments, as price of entry and time arbitrage should also be taken into account. People should also be aware that most investing is very narrative-driven, and the narrative can sometimes overpower all other elements that one should be doing to get a full picture of why they should be buying something. Finally, if people are not passionate and curious about studying and learning about stocks and businesses, they should not do it, as the analytical depth and rigor required to be successful in investing takes practice and discipline.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1678604856,\n",
      "  \"id\": \"chatcmpl-6tA5oqvXrFMT3xoZXOWZ0lkIcTGyZ\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 166,\n",
      "    \"prompt_tokens\": 3309,\n",
      "    \"total_tokens\": 3475\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f9218e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n"
     ]
    }
   ],
   "source": [
    "print(timestamps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fdc6455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['kind', 'videoId'])\n"
     ]
    }
   ],
   "source": [
    "print(everyDct['items'][0]['id'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdda70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everyDct -> thumbnails\n",
    "def get_thumbnails(everyDct):\n",
    "    thumbnails = {}\n",
    "    for i in range(len(everyDct['items'])):\n",
    "        thumbnails[i] = everyDct['items'][0]['snippet']['thumbnails']\n",
    "    return thumbnails\n",
    "\n",
    "# everyDct -> Ids\n",
    "def get_ids():\n",
    "    items = everyDct['items']\n",
    "    lstOfIds = {}\n",
    "    x = 0\n",
    "    for i in range(len(items)):\n",
    "        lstOfIds[x] = items[i]['id']['videoId']\n",
    "        x = x + 1\n",
    "    return lstOfIds\n",
    "\n",
    "# everyDct -> timestamps\n",
    "def get_timestamps():\n",
    "    timestamps = {}\n",
    "    for i in range(len(everyDct['items'])):\n",
    "        timestamps[i] = linkToDict(everyDct['items'][i]['id']['videoId'])\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "# Ids -> Transcript\n",
    "def get_transcripts(lstofids):\n",
    "    transcriptDct = {}\n",
    "    for i in range(len(lstofids)):\n",
    "        temp = YouTubeTranscriptApi.get_transcript(lstofids[i])\n",
    "        transcriptDct[i]=temp\n",
    "    return transcriptDct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d06c4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescription(link):\n",
    "    soup = BeautifulSoup(requests.get('https://www.youtube.com/watch?v=' + str(link)).content)\n",
    "    pattern = re.compile('(?<=shortDescription\":\").*(?=\",\"isCrawlable)')\n",
    "    description = pattern.findall(str(soup))[0].replace('\\\\n','\\n')\n",
    "    return description\n",
    "\n",
    "def en(number):\n",
    "    # Extract number\n",
    "    return re.sub('[^0-9]','', number)\n",
    "    \n",
    "def extracTimeStamps(description):\n",
    "    lines = []\n",
    "    for line in description.splitlines():\n",
    "        if len(line)<3:\n",
    "            continue\n",
    "        if line[1]==\":\" or line[2] == \":\" or line[3]==\":\":\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "def infoFromTimeStamps(line):\n",
    "#     print(line)\n",
    "    timeStamp = line.split()[0]\n",
    "   \n",
    "    if len(timeStamp)>5 and timeStamp[5] == 'H':\n",
    "        timeStamp = timeStamp[:5]\n",
    "    times = timeStamp.split(':')\n",
    "   \n",
    "    english = en(times[-1])\n",
    "    if (len(english) < 1):\n",
    "        return None\n",
    "    seconds = int(english)\n",
    "    val = 4\n",
    "    if len(times) == 3:\n",
    "        seconds+=int(en(times[0])) * 3600\n",
    "        seconds += int(en(times[1])) * 60\n",
    "        val = 8\n",
    "    if len(times) == 2:\n",
    "        seconds += int(en(times[0])) * 60\n",
    "        val = 6\n",
    "    \n",
    "    return (seconds, line[val:].strip())\n",
    "\n",
    "def timeStampsToList(timeStamps):\n",
    "    \n",
    "    ans = []\n",
    "    for line in timeStamps:\n",
    "        lst = []\n",
    "        tempAns = infoFromTimeStamps(line)\n",
    "        if tempAns is None:\n",
    "            continue\n",
    "        (time, line) = tempAns\n",
    "        lst.append(time)\n",
    "        lst.append(line)\n",
    "        ans.append(lst)\n",
    "    return ans\n",
    "\n",
    "\n",
    "def timeStampsToDict(timeStamps):\n",
    "    dct = {}\n",
    "    for line in timeStamps:\n",
    "        (time, line) = infoFromTimeStamps(line)\n",
    "        dct[time]=line\n",
    "    return dct\n",
    "\n",
    "def linkToDict(link):\n",
    "    description = getDescription(link)\n",
    "#     print(description)\n",
    "    timeStamps = extracTimeStamps(description)\n",
    "#     dct = timeStampsToDict(timeStamps)\n",
    "    dct = timeStampsToList(timeStamps)\n",
    "    return dct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b2a9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video's transcript + videos timestamps -> corrected transcript\n",
    "def create_correct_dct_for_section(oneThWords, oneThTimes):\n",
    "    x = 0\n",
    "    currentDct = {}\n",
    "    currentTxt = \"\"\n",
    "    if len(oneThTimes) == 0:\n",
    "        return None\n",
    "    currentTime = oneThTimes[x][0]\n",
    "\n",
    "    for i in range(len(oneThWords)-1):\n",
    "        time = oneThWords[i]['start']\n",
    "        text = oneThWords[i]['text']\n",
    "        if (x==len(oneThTimes)-1):\n",
    "            currentTxt = currentTxt + \" \" + text.strip()\n",
    "            continue\n",
    "        if (float(time) >= float(oneThTimes[x+1][0])):\n",
    "            currentDct[currentTime]= currentTxt\n",
    "            x = x + 1\n",
    "            currentTxt = \"\"\n",
    "            currentTime = oneThTimes[x][0]\n",
    "        currentTxt = currentTxt + \" \" + text.strip()\n",
    "\n",
    "\n",
    "    currentTxt = currentTxt + \" \" + oneThWords[len(oneThWords)-1]['text']\n",
    "    currentDct[oneThTimes[len(oneThTimes)-1][0]]= currentTxt\n",
    "    return currentDct\n",
    "\n",
    "# everyDct -> segmented transcript dict\n",
    "def create_corrected_dct_for_channel():\n",
    "    segmented_transcripts = {}\n",
    "    for i in range(len(transcripts)):\n",
    "        current = create_correct_dct_for_section(transcripts[i], timestamps[i])\n",
    "        if current is None:\n",
    "            continue\n",
    "        segmented_transcripts[i] = current\n",
    "    return segmented_transcripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5da8514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(input_string):\n",
    "    response = openai.Embedding.create(\n",
    "        input=input_string,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    return np.dot(A,B)/(norm(A)*norm(B))\n",
    "\n",
    "\n",
    "def turn_to_embeddings():\n",
    "    embeddings = {}\n",
    "    for i in range(len(segmented_transcripts)):\n",
    "        if i not in segmented_transcripts.keys():\n",
    "            continue\n",
    "        toPassInDct = vectorize_section(segmented_transcripts[i])\n",
    "        embeddings[i] = toPassInDct\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def vectorize_phrase(phrase):\n",
    "    response = openai.Embedding.create(\n",
    "        input=phrase[:5000],\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "def vectorize_section(section):\n",
    "    toAdd = {}\n",
    "    for i in section.keys():\n",
    "        toAdd[i] = vectorize_phrase(section[i])\n",
    "    return toAdd\n",
    "\n",
    "\n",
    "\n",
    "def getClosestEmbedding(odct, query, seen):\n",
    "    query = getEmbedding(query)\n",
    "    \n",
    "    closest = 0\n",
    "    closestPairing = (0,0)\n",
    "    \n",
    "    for d in odct.keys():\n",
    "        if str(d).strip() == \"0\":\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for x in odct[d].keys():\n",
    "            emb = odct[d][x]\n",
    "            cosine = cosine_similarity(emb, query)\n",
    "            if (cosine > closest and cosine not in seen):\n",
    "                closest = cosine\n",
    "                closestPairing = (d, x)\n",
    "\n",
    "\n",
    "    return (closestPairing, closest)\n",
    "\n",
    "def get_video_link(time, nId):\n",
    "#     print(str(Sands['items'][nId]['snippet']['resourceId']['videoId']))\n",
    "    link = (\"https://www.youtube.com/watch?v=\" + str(everyDct['items'][nId]['id']['videoId'])  + \"&t=\" + str(time) + \"s\")\n",
    "    title = str(everyDct['items'][nId]['snippet']['title'])\n",
    "    iterate = timestamps[nId+1]\n",
    "#     print(nId)\n",
    "#     print(iterate)\n",
    "    ans = \"Video\"\n",
    "    for i in iterate:\n",
    "#         print(i)\n",
    "        if str(i[0]).strip() == str(time).strip():\n",
    "            ans = i[1]\n",
    "            break\n",
    "    return (link, title, ans)\n",
    "\n",
    "def get_context(query):\n",
    "    \n",
    "    ret = \"\"\n",
    "    seen = []\n",
    "    for i in range(3):\n",
    "        (tup, toAdd) = getClosestEmbedding(overArchingDct, query, seen)\n",
    "        seen.append(toAdd)\n",
    "        ret = ret + \" \" + str(segmented_transcripts[tup[0]][tup[1]])\n",
    "        \n",
    "    return (ret[:3500], tup[0], tup[1])\n",
    "\n",
    "def answer(query, person_background):\n",
    "    ans = get_context(query)\n",
    "    context = ans[0]\n",
    "#     print(context)\n",
    "#     print(get_video_link(int(ans[2]), int(ans[1])))\n",
    "    \n",
    "    return (openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": person_background},\n",
    "#             {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": query + \" Respond in a few full sentences. Use the following context: \\\"\"  + context + \"\\\"\"}\n",
    "      ]\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578cb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
